# Derin Ã–ÄŸrenme (Deep Learning)

ğŸ“’[Ders SlaytlarÄ± (Lecture Slides)](https://github.com/elifbeyzatok00/Deep-Learning/tree/main/slaytlar)

ğŸ“Œ[Laboratuvar KodlarÄ± (Laboratory Codes)](https://github.com/elifbeyzatok00/Deep-Learning/tree/main/Labaratuvar%20Kodlar%C4%B1)

ğŸ“”[Ders NotlarÄ± (Lecture Notes) â­](https://github.com/elifbeyzatok00/Deep-Learning/blob/main/Derin%20%C3%96%C4%9Freme%20Ders%20Notlar%C4%B1%202023-2024.pdf)

---
### 1. Derin Ã–ÄŸrenmeye GiriÅŸ (Introduction to Deep Learning)
Derin Ã¶ÄŸrenme, makine Ã¶ÄŸrenmesinin bir alt dalÄ±dÄ±r ve yapay sinir aÄŸlarÄ±nÄ±n katmanlarÄ±nÄ±n artmasÄ±yla daha karmaÅŸÄ±k ve yÃ¼ksek doÄŸruluklu modeller oluÅŸturmayÄ± hedefler. Derin Ã¶ÄŸrenme, bÃ¼yÃ¼k veri kÃ¼melerini ve gÃ¼Ã§lÃ¼ iÅŸlem kaynaklarÄ±nÄ± kullanarak gÃ¶rÃ¼ntÃ¼ tanÄ±ma, ses tanÄ±ma, dil iÅŸleme gibi birÃ§ok alanda etkileyici sonuÃ§lar elde eder.

ğŸ”—[Derin Ã–ÄŸrenmeye GiriÅŸ (Introduction to Deep Learning)](https://github.com/elifbeyzatok00/Deep-Learning/blob/main/slaytlar/1-Derin%20Ogrenmeye%20Giris.pptx)

### 2. Ã‡ok KatmanlÄ± Sinir AÄŸlarÄ± (Multilayer Neural Networks)
Ã‡ok katmanlÄ± sinir aÄŸlarÄ± (MLP - Multi-Layer Perceptron), bir giriÅŸ katmanÄ±, bir veya daha fazla gizli katman ve bir Ã§Ä±kÄ±ÅŸ katmanÄ±ndan oluÅŸur. Her bir katman, bir Ã¶nceki katmandan gelen bilgiyi iÅŸler ve bir sonraki katmana ileterek, karmaÅŸÄ±k iliÅŸkileri Ã¶ÄŸrenir. Geri yayÄ±lÄ±m (backpropagation) algoritmasÄ±, bu aÄŸlarÄ±n eÄŸitilmesinde kullanÄ±lÄ±r.

ğŸ”—[Ã‡ok KatmanlÄ± Sinir AÄŸlarÄ± (Multilayer Neural Networks)](https://github.com/elifbeyzatok00/Deep-Learning/blob/main/slaytlar/2-%20Cok%20Katmanl%C4%B1%20Sinir%20A%C4%9Flar%C4%B1.pptx)

### 3. Derin Ã–ÄŸrenme Temelleri (Deep Learning Fundamentals)
Derin Ã¶ÄŸrenme temelleri, sinir aÄŸlarÄ±nÄ±n yapÄ±sÄ±nÄ±, aktivasyon fonksiyonlarÄ±nÄ±, optimizasyon algoritmalarÄ±nÄ± ve model deÄŸerlendirme metriklerini kapsar. Temel kavramlar arasÄ±nda lineer olmayan dÃ¶nÃ¼ÅŸÃ¼mler, overfitting/underfitting, dropout, regularizasyon ve veri artÄ±rma (data augmentation) bulunur.

ğŸ”—[Derin Ã–ÄŸrenme Temelleri (Deep Learning Fundamentals)](https://github.com/elifbeyzatok00/Deep-Learning/blob/main/slaytlar/3-Derin%20Ogrenme%20Temelleri.pptx)

### 4. EvriÅŸimli Sinir AÄŸlarÄ± (CNN - Convolutional Neural Networks)
EvriÅŸimli sinir aÄŸlarÄ±, Ã¶zellikle gÃ¶rÃ¼ntÃ¼ iÅŸleme ve bilgisayarla gÃ¶rme alanÄ±nda kullanÄ±lan bir sinir aÄŸÄ± tÃ¼rÃ¼dÃ¼r. CNN'ler, giriÅŸ gÃ¶rÃ¼ntÃ¼lerinden Ã¶zellikleri otomatik olarak Ã§Ä±karan ve bu Ã¶zellikleri sÄ±nÄ±flandÄ±ran evriÅŸim katmanlarÄ± (convolutional layers), havuzlama katmanlarÄ± (pooling layers) ve tam baÄŸlÄ± katmanlardan (fully connected layers) oluÅŸur.

ğŸ”—[EvriÅŸimli Sinir AÄŸlarÄ± (CNN - Convolutional Neural Networks)](https://github.com/elifbeyzatok00/Deep-Learning/blob/main/slaytlar/4-Evrisimli%20Sinir%20Aglar%C4%B1.pptx)

### 5. Ãœretici Ã‡ekiÅŸmeli AÄŸlar (GAN - Generative Adversarial Networks)
Ãœretici Ã§ekiÅŸmeli aÄŸlar, iki sinir aÄŸÄ±ndan oluÅŸur: bir Ã¼retici (generator) ve bir ayrÄ±ÅŸtÄ±rÄ±cÄ± (discriminator). Ãœretici aÄŸ, gerÃ§ekÃ§i veriler Ã¼retmeye Ã§alÄ±ÅŸÄ±rken, ayrÄ±ÅŸtÄ±rÄ±cÄ± aÄŸ, gerÃ§ek verileri sahte verilerden ayÄ±rt etmeye Ã§alÄ±ÅŸÄ±r. Bu iki aÄŸ, birbirine karÅŸÄ± yarÄ±ÅŸarak, gerÃ§ekÃ§i ve yÃ¼ksek kaliteli veri Ã¼retimi saÄŸlar. GAN'lar, gÃ¶rÃ¼ntÃ¼ oluÅŸturma, ses sentezi ve veri artÄ±rma gibi birÃ§ok alanda kullanÄ±lÄ±r.

ğŸ”—[Ãœretici Ã‡ekiÅŸmeli AÄŸlar (GAN - Generative Adversarial Networks)]()

### 6. Perceptron
Perceptron, yapay sinir aÄŸlarÄ±nÄ±n en basit formudur ve tek bir sinir hÃ¼cresinden (nÃ¶ron) oluÅŸur. Girdi olarak aldÄ±ÄŸÄ± verileri aÄŸÄ±rlÄ±klarla Ã§arpar, ardÄ±ndan bu aÄŸÄ±rlÄ±klÄ± toplamÄ± bir eÅŸik deÄŸerle karÅŸÄ±laÅŸtÄ±rarak karar verir. EÅŸik deÄŸeri aÅŸan Ã§Ä±ktÄ±lar iÃ§in bir aktivasyon fonksiyonu uygulanÄ±r. Perceptron, iki sÄ±nÄ±fÄ± ayÄ±rmak iÃ§in kullanÄ±lÄ±r ve doÄŸrusal olarak ayrÄ±labilen verilerde etkilidir.

ğŸ”—[Perceptron](https://github.com/elifbeyzatok00/Deep-Learning/blob/main/Labaratuvar%20Kodlar%C4%B1/1-Perceptron.ipynb)

### 7. CNN AdÄ±mlarÄ± (CNN Steps)
CNN'lerin temel adÄ±mlarÄ± ÅŸunlardÄ±r:
1. **EvriÅŸim (Convolution):** GiriÅŸ gÃ¶rÃ¼ntÃ¼sÃ¼ Ã¼zerinde filtreler (kernels) uygulanarak Ã¶zellik haritalarÄ± oluÅŸturulur.
2. **Aktivasyon (Activation):** Genellikle ReLU (Rectified Linear Unit) aktivasyon fonksiyonu kullanÄ±larak, negatif deÄŸerler sÄ±fÄ±rlanÄ±r ve doÄŸrusal olmayan dÃ¶nÃ¼ÅŸÃ¼m saÄŸlanÄ±r.
3. **Havuzlama (Pooling):** Ã–zellik haritalarÄ±nÄ±n boyutunu kÃ¼Ã§Ã¼ltmek ve hesaplama maliyetini azaltmak iÃ§in maksimum veya ortalama havuzlama (max pooling veya average pooling) uygulanÄ±r.
4. **Tam BaÄŸlÄ± Katman (Fully Connected Layer):** Havuzlama katmanlarÄ±ndan gelen veriler, dÃ¼zleÅŸtirilir ve tam baÄŸlÄ± katmanlara iletilir. Bu katmanlar, sÄ±nÄ±flandÄ±rma veya regresyon gÃ¶revini yerine getirir.
5. **Ã‡Ä±kÄ±ÅŸ KatmanÄ± (Output Layer):** Son katmanda, genellikle softmax aktivasyon fonksiyonu kullanÄ±larak sÄ±nÄ±flandÄ±rma sonuÃ§larÄ± elde edilir.

ğŸ”—[CNN AdÄ±mlarÄ± (CNN Steps)](https://github.com/elifbeyzatok00/Deep-Learning/tree/main/Labaratuvar%20Kodlar%C4%B1/2-CNN%20Ad%C4%B1mlar%C4%B1)

### 8. Yapay Sinir AÄŸlarÄ± (ANN - Artificial Neural Networks)
Yapay sinir aÄŸlarÄ±, insan beynindeki sinir hÃ¼crelerinin Ã§alÄ±ÅŸma prensibini taklit eden hesaplama modelleridir. Temel bileÅŸenleri nÃ¶ronlar, aÄŸÄ±rlÄ±klar, aktivasyon fonksiyonlarÄ± ve katmanlardÄ±r. Bir ANN genellikle bir giriÅŸ katmanÄ±, bir veya daha fazla gizli katman ve bir Ã§Ä±kÄ±ÅŸ katmanÄ±ndan oluÅŸur. NÃ¶ronlar, girdileri iÅŸleyip aktivasyon fonksiyonlarÄ± aracÄ±lÄ±ÄŸÄ±yla Ã§Ä±ktÄ±lar Ã¼retir. Bu aÄŸlar, Ã¶ÄŸrenme sÃ¼recinde aÄŸÄ±rlÄ±klarÄ±nÄ± ayarlayarak verilerdeki desenleri Ã¶ÄŸrenirler. ANN'ler, Ã§eÅŸitli makine Ã¶ÄŸrenmesi ve derin Ã¶ÄŸrenme gÃ¶revlerinde kullanÄ±lÄ±r.

ğŸ”—[Yapay Sinir AÄŸlarÄ± (ANN - Artificial Neural Networks)](https://github.com/elifbeyzatok00/Deep-Learning/blob/main/Labaratuvar%20Kodlar%C4%B1/3-ANN_Delta.ipynb)
